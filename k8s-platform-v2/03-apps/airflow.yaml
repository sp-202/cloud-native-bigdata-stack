apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-webserver
  template:
    metadata:
      labels:
        app: airflow-webserver
    spec:
      securityContext:
        fsGroup: 50000
      initContainers:
      - name: wipe-old-files
        image: busybox
        # Use simple check or just skip wipe if sharing volume actively
        # For hostPath sharing, maybe don't wipe? 
        # Ideally, git-sync manages the repo.
        # Let's keep it simple: git-sync owns the repo folder.
        command: ["sh", "-c", "echo 'Shared Volume Mode'"] 
        volumeMounts:
        - name: dags-data
          mountPath: /opt/airflow/dags
      containers:
      - name: airflow-webserver
        image: apache/airflow:2.7.1
        args: ["webserver"]
        env:
        - name: AIRFLOW__CORE__EXECUTOR
          value: "LocalExecutor"
        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          value: "postgresql+psycopg2://airflow:airflow@postgres.default.svc.cluster.local/airflow"
        - name: AIRFLOW__CORE__FERNET_KEY
          value: "46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho="
        - name: AIRFLOW__CORE__LOAD_EXAMPLES
          value: "False"
        - name: AIRFLOW__CORE__DAGS_FOLDER
          value: "/opt/airflow/dags/repo" # Git-sync syncs to <root>/repo
        volumeMounts:
        - name: dags-data
          mountPath: /opt/airflow/dags # Mount shared PVC here
          readOnly: true # Webserver just reads

      volumes:
      - name: dags-data
        persistentVolumeClaim:
          claimName: airflow-dags-shared-pvc # Use shared PVC
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-scheduler
  template:
    metadata:
      labels:
        app: airflow-scheduler
    spec:
      securityContext:
        fsGroup: 50000
      containers:
      - name: airflow-scheduler
        image: apache/airflow:2.7.1
        args: ["scheduler"]
        env:
        - name: AIRFLOW__CORE__EXECUTOR
          value: "LocalExecutor"
        - name: AIRFLOW__CORE__SQL_ALCHEMY_CONN
          value: "postgresql+psycopg2://airflow:airflow@postgres.default.svc.cluster.local/airflow"
        - name: AIRFLOW__CORE__FERNET_KEY
          value: "46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho="
        - name: AIRFLOW__CORE__DAGS_FOLDER
          value: "/opt/airflow/dags/repo"
        volumeMounts:
        - name: dags-data
          mountPath: /opt/airflow/dags
          readOnly: true

      volumes:
      - name: dags-data
        persistentVolumeClaim:
          claimName: airflow-dags-shared-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: airflow-webserver
  namespace: default
spec:
  ports:
  - port: 8080
    targetPort: 8080
    name: web
  selector:
    app: airflow-webserver