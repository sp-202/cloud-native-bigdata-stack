# =============================================================================
# Spark Configuration (Kubernetes) - Generated for Local Use
# =============================================================================

# --- Application & Naming ---
spark.app.name                   spark-bigdata
spark.kubernetes.executor.podNamePrefix spark-executor

# --- Master & Deployment ---
spark.master                     k8s://https://127.0.0.1:6443
spark.submit.deployMode          client
spark.kubernetes.namespace       default
spark.kubernetes.container.image subhodeep2022/spark-bigdata:spark-4.0.1-uc-0.3.1-fix-v6-proper-way
spark.kubernetes.authenticate.driver.serviceAccountName spark-operator-spark

# --- SQL & ANSI Mode ---
spark.sql.ansi.enabled           false

# --- Dynamic Resource Allocation ---
spark.dynamicAllocation.enabled              true
spark.dynamicAllocation.shuffleTracking.enabled true
spark.dynamicAllocation.minExecutors         1
spark.dynamicAllocation.maxExecutors         5
spark.dynamicAllocation.executorIdleTimeout  600

# --- Networking & Timeouts ---
spark.network.timeout            120
spark.files.fetchTimeout         60
spark.executor.heartbeatInterval 10

# --- Hadoop S3A Configuration ---
spark.hadoop.fs.s3a.threads.keepalivetime    60
spark.hadoop.fs.s3a.connection.timeout       200
spark.hadoop.fs.s3a.connection.establish.timeout 30
spark.hadoop.fs.s3a.connection.acquisition.timeout 60
spark.hadoop.fs.s3a.multipart.purge.age      86400

# --- Executor & Driver Resources ---
spark.executor.cores             1
spark.executor.memory            2g
spark.driver.cores               1
spark.driver.memory              2g

# --- Metrics & Monitoring ---
spark.ui.prometheus.enabled      true
spark.metrics.namespace          spark

# --- SQL & Catalogs (Delta Lake & Hive) ---
spark.sql.extensions             io.delta.sql.DeltaSparkSessionExtension
spark.sql.defaultCatalog         spark_catalog
spark.sql.catalog.spark_catalog  org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.sql.catalogImplementation  hive
spark.hadoop.hive.metastore.uris thrift://hive-metastore.default.svc.cluster.local:9083
spark.sql.warehouse.dir          s3a://warehouse/managed/

# --- S3 / MinIO Configuration ---
spark.hadoop.fs.s3a.impl                 org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3.impl                  org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.path.style.access    true
spark.hadoop.fs.s3a.connection.ssl.enabled false
spark.hadoop.fs.s3a.aws.credentials.provider org.apache.hadoop.fs.s3a.auth.EnvironmentVariableCredentialsProvider,org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.endpoint             http://minio.default.svc.cluster.local:9000

# --- Networking & UI ---
# Bind to all interfaces for container/pod access
spark.ui.bindHost                        0.0.0.0
spark.ui.port                            4040
spark.driver.bindAddress                 0.0.0.0
